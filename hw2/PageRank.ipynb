{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark import SparkConf, SparkContext\n",
    "f = open(\"/Users/mencher/Projects/big_data/Outputfile.txt\", 'a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report\n",
    "本次作業要求用 Map-Reduce，計算 page rank 的值，以下為本次實作的步驟：\n",
    "1. 初始化 PySpark ，讀入檔案後，首先將檔案逐行拆分。由於測資的樣本格式為 `<in-node> <out-node> (ex: 1 2)`，需再依據 Tab 分隔並產生 Python List（如：`[1, 2]`），方便後續存取，並透過 flatMap 輸出 rdd 格式。\n",
    "\n",
    "2. 由於存在部分點只有 In-Node 沒有 Out-Node ，或只有 Out-Node 沒有 In-Node，我先分別計算只有 In-Node ，與只有 Out-Node 的，再透過 Union 在兩者取合集，找出全部的 Node 。\n",
    "\n",
    "3. 然則，在計算中，當某個 Node 沒有 in-link （別人接給他），只有 out-link (他接到別人) 時，該點會在計算中遺失。也因此，對於這些特別的 Node，我補了自己接到自己的線，並讓其的 wight 預設為 0。透過這個設計，我們可避免計算中該 Node 遺失。\n",
    "\n",
    "4. 在此部分，我試圖初始化 Pagerank。這部分的目標會生成兩種 Map，第一種 Map `totalMap` 負責記錄自己和他人的連線，第二種 Map `currentState` 負責記錄自己的 pagerank。\n",
    "\n",
    "**totalMap的整理：**\n",
    "```python\n",
    "totalMap = splittedData.map(lambda val: (val[0], [val[1]])).reduceByKey(lambda x,y: x+y)\n",
    "```\n",
    "這部分會先將資料整理成 `(<in-node>, [<out-node1>, <out-node2>, <out-node3>])`，ex: `(1, [ 2, 4 ])`\n",
    "```python\n",
    ".flatMap(expandTotalMap)\n",
    "\n",
    "def expandTotalMap(val):\n",
    "    concatItem = []\n",
    "    for item in val[1]:\n",
    "        totalNum = len(val[1])\n",
    "        concatItem.append((val[0], (item, 1/totalNum)))\n",
    "    return concatItem\n",
    "```\n",
    "則是再度把整理的 value array 展開，賦予每個 out-link weight。weight 則是看自己共發散出幾條邊，進行平均。最終處理成 `(<in-node>, (<out-node>, <line weight>))`，ex: `(1, (2, 0.5)) 與 (1, (4, 0.5))`\n",
    "\n",
    "\n",
    "```python\n",
    ".union(additionalRelation)\n",
    "```\n",
    "再將只有 out-link ，但沒有 in-link 的點，補一個自己接自己的線。\n",
    "\n",
    "**currentState的整理：**\n",
    "```python\n",
    "currentState = totalNode.map(lambda val: (val, 1/totalNodeNum))\n",
    "```\n",
    "進行初始化，每個點先平均分配 `1/<全部點個數>`。\n",
    "\n",
    "\n",
    "5. 接續便要進行 `for-loop` 的持續更新，進行 pagerank 的計算。我們依照以下公式進行計算：\n",
    "\n",
    "<img src=\"./equation.png\" width=\"400px\" />\n",
    "\n",
    "並將 beta 設為 0.8 ， iteration 設為 20 次\n",
    "```python\n",
    "joinResult = totalMap.join(currentState).map(lambda val: (val[1][0][0], val[1][0][1]*val[1][1]*beta)).reduceByKey(lambda x, y: x+y)\n",
    "```\n",
    "此步驟每個 Node ，算出自己對每個 out-link 的 Contribution，將`<自己的pagerank>*<out-link 每條線的 weight>*beta` 後，再進行加總。\n",
    "\n",
    "```python\n",
    "_sum = joinResult.values().sum()\n",
    "currentState = joinResult.map(lambda val: (val[0], ((1 - _sum)/totalNodeNum) + val[1]))\n",
    "```\n",
    "此步驟進行 Normalize ，因為每次計算的 pagerank 不一定加總起來為 1 。因此，我們先算出目前 pagerank 的加總(`_sum`)，再用 `1 - _sum`後取平均，並分配到每個 Node 身上，完成一次 Normalization。\n",
    "\n",
    "以上步驟進行 20 次後，即完成 pagerank 計算。\n",
    "\n",
    "6.  因應輸出需求，將結果依據 pagerank 值進行 sorting，並四捨五入後只取其前三位數，寫到 output file。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1056\t0.000632\n",
      "\n",
      "1054\t0.000629\n",
      "\n",
      "1536\t0.000524\n",
      "\n",
      "171\t0.000512\n",
      "\n",
      "453\t0.000496\n",
      "\n",
      "407\t0.000485\n",
      "\n",
      "263\t0.000480\n",
      "\n",
      "4664\t0.000470\n",
      "\n",
      "261\t0.000463\n",
      "\n",
      "410\t0.000462\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# union, count\n",
    "# sum -> 不用 collect\n",
    "\n",
    "totalEdgesNum = 0\n",
    "beta = 0.8\n",
    "\n",
    "def splitLines(lines):\n",
    "    global totalEdgesNum\n",
    "    splitedItems = []\n",
    "    for perLine in lines.splitlines():\n",
    "        totalEdgesNum = totalEdgesNum + 1\n",
    "        splitedItems.append(perLine.split('\\t'))\n",
    "    return splitedItems\n",
    "    \n",
    "def expandTotalMap(val):\n",
    "    concatItem = []\n",
    "    for item in val[1]:\n",
    "        totalNum = len(val[1])\n",
    "        concatItem.append((val[0], (item, 1/totalNum)))\n",
    "    return concatItem\n",
    "\n",
    "# 1. First Step\n",
    "conf = SparkConf().setMaster(\"local\").setAppName(\"pagerank\")\n",
    "sc = SparkContext.getOrCreate(conf=conf)\n",
    "splittedData = sc.textFile(\"./input.txt\").flatMap(splitLines)\n",
    "\n",
    "# 2. Second Step\n",
    "inNodes = splittedData.map(lambda val: val[0]).distinct()\n",
    "outNodes = splittedData.map(lambda val: val[1]).distinct()\n",
    "totalNode = inNodes.union(outNodes).distinct()\n",
    "totalNodeNum = totalNode.count()\n",
    "\n",
    "# 3. Third Step\n",
    "additionalRelation = inNodes.subtract(outNodes).map(lambda val: (val, (val, 0)))\n",
    "\n",
    "# 4. Forth Step\n",
    "totalMap = splittedData.map(lambda val: (val[0], [val[1]])).reduceByKey(lambda x,y: x+y).flatMap(expandTotalMap).union(additionalRelation)\n",
    "currentState = totalNode.map(lambda val: (val, 1/totalNodeNum))\n",
    "\n",
    "# 5. Fifth Step\n",
    "for _ in range(20):\n",
    "    joinResult = totalMap.join(currentState).map(lambda val: (val[1][0][0], val[1][0][1]*val[1][1]*beta)).reduceByKey(lambda x, y: x+y)\n",
    "    _sum = joinResult.values().sum()\n",
    "    currentState = joinResult.map(lambda val: (val[0], ((1 - _sum)/totalNodeNum) + val[1]))\n",
    "\n",
    "\n",
    "# 6. Fifth Step\n",
    "sorted_result = currentState.sortBy(lambda x: x[1], ascending=False)\n",
    "for item in sorted_result.collect()[0:10]:\n",
    "    f.write('%s\\t%f\\n'%(item[0], item[1]))\n",
    "    print('%s\\t%f\\n'%(item[0], item[1]))\n",
    "f.close()\n",
    "sc.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
