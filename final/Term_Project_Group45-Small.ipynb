{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark import SparkConf, SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(8, [(4, 0.6000000000000001), (6, -0.6000000000000001)]),\n",
       " (4, [(5, -0.3333333333333335), (2, 0.8333333333333335), (3, -2.0)]),\n",
       " (12, [(5, 1.6666666666666665), (2, -0.16666666666666652)]),\n",
       " (5, [(4, 1.6), (5, 0.6666666666666665), (6, 0.3999999999999999), (3, -1.0)]),\n",
       " (1, [(1, -2.6), (6, -1.6), (3, -1.0)]),\n",
       " (9, [(1, 1.4), (3, 1.0)]),\n",
       " (2, [(4, -1.4), (3, 1.0)]),\n",
       " (6, [(1, 1.4), (5, -1.3333333333333335)]),\n",
       " (10, [(2, -1.1666666666666665), (3, 0.0)]),\n",
       " (3,\n",
       "  [(4, 0.6000000000000001),\n",
       "   (1, -0.6000000000000001),\n",
       "   (5, 0.6666666666666665),\n",
       "   (6, 0.3999999999999999),\n",
       "   (2, 1.8333333333333335)]),\n",
       " (11,\n",
       "  [(4, -1.4),\n",
       "   (1, 0.3999999999999999),\n",
       "   (5, -1.3333333333333335),\n",
       "   (6, 1.4),\n",
       "   (2, -2.1666666666666665),\n",
       "   (3, 2.0)]),\n",
       " (7, [(2, 0.8333333333333335), (3, 0.0)])]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "from itertools import islice\n",
    "\n",
    "# Output : (movie_id, (user_id, rating))\n",
    "def readData(lines):\n",
    "    output = []\n",
    "    for perLine in lines.splitlines():\n",
    "        splitedItems = perLine.split(',')\n",
    "        if (splitedItems[0] == 'userId'): continue\n",
    "        output.append((int(splitedItems[1]), (int(splitedItems[0]), float(splitedItems[2]))))\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "# Output: (movie_id, consineBottom)\n",
    "def calConsineBottom(data):\n",
    "    ratingSum = 0\n",
    "    for userRatingTriple in data[1]:\n",
    "        userRating = userRatingTriple[1]\n",
    "        ratingSum = ratingSum + pow(userRating, 2)\n",
    "    squaredRatingSum = math.sqrt(ratingSum)\n",
    "    return (data[0], squaredRatingSum)\n",
    "        \n",
    "# Output: (user_id, [(movie_id, user_rating)])\n",
    "def convertedToUserKey(data):\n",
    "    expandedData = []\n",
    "    movieId = data[0]\n",
    "    for userRatingTriple in data[1]:\n",
    "        userId = userRatingTriple[0]\n",
    "        userRating = userRatingTriple[1]\n",
    "        expandedData.append((userId, [(movieId, userRating)]))\n",
    "    return expandedData\n",
    "\n",
    "\n",
    "conf = SparkConf().setMaster(\"local\").setAppName(\"recommendation\").set(\"spark.default.parallelism\", 4).set('spark.driver.memory', '45G').set('spark.driver.maxResultSize', '10G')\n",
    "sc = SparkContext.getOrCreate(conf=conf)\n",
    "originalData = sc.textFile(\"./ratings-small.csv\").flatMap(readData)\n",
    "\n",
    "# Output: (movie_id, movie_id_avg_rating)\n",
    "movieAvgs = originalData.map(lambda data: (data[0], (1, data[1][1]))).reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1])).map(lambda data: (data[0], data[1][1]/data[1][0]))\n",
    "\n",
    "# After join, reducer do \"some_rating - avg_rating\"\n",
    "# Output: (movie_id, [(user_id, modified_rating)])\n",
    "joinedData = originalData.join(movieAvgs).map(lambda data: (data[0], [(data[1][0][0], (data[1][0][1] - data[1][1]))]))\n",
    "\n",
    "# Output: (movie_id, [(user_id1, modified_rating1), (user_id2, modified_rating2), ...])\n",
    "joinedData = joinedData.reduceByKey(lambda x, y: x+y)\n",
    "\n",
    "consineBottom = joinedData.map(calConsineBottom)\n",
    "# Output: (user_id, [(movie_id1, user_rating1), (movie_id2, user_rating2)])\n",
    "convertedToUserKeyData = joinedData.flatMap(convertedToUserKey).reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "convertedToUserKeyData.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((4, 6), -1.44),\n",
       " ((1, 5), -2.8),\n",
       " ((2, 4), 4.133333333333333),\n",
       " ((2, 3), -6.0),\n",
       " ((4, 5), 3.333333333333333),\n",
       " ((5, 6), -1.3333333333333335),\n",
       " ((3, 4), -5.8),\n",
       " ((1, 6), 4.48),\n",
       " ((1, 2), -1.9666666666666668),\n",
       " ((3, 5), -2.6666666666666665),\n",
       " ((1, 3), 4.8),\n",
       " ((2, 6), -2.2999999999999994),\n",
       " ((2, 5), 3.5555555555555554),\n",
       " ((3, 6), 4.0),\n",
       " ((1, 4), -0.9199999999999999)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output: ((movie_id1, movie_id2), some_rating)\n",
    "def moviePairMapping(data):\n",
    "    exportedData = []\n",
    "    for OuterMovieRatingPair in data[1]:\n",
    "        for innerMovieRatingPair in data[1]:\n",
    "            firstMovieId = OuterMovieRatingPair[0]\n",
    "            secondMovieId = innerMovieRatingPair[0]            \n",
    "            if (firstMovieId >= secondMovieId): continue\n",
    "\n",
    "            firstMovieUserRating = OuterMovieRatingPair[1]\n",
    "            secondMovieUserRating = innerMovieRatingPair[1]\n",
    "            productRating = firstMovieUserRating*secondMovieUserRating\n",
    "\n",
    "            exportedData.append(((firstMovieId, secondMovieId), productRating))\n",
    "\n",
    "    return exportedData\n",
    "\n",
    "consineTop = convertedToUserKeyData.flatMap(moviePairMapping).reduceByKey(lambda x, y: x + y)\n",
    "consineTop.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim_pair: ((sim_movie_id1, sim_movie_id2), similarity)\n",
    "\n",
    "consineTop = consineTop.filter(lambda data: data[1] != 0)\n",
    "\n",
    "# Output: (sim_movie1, ((sim_pair), sim_movie1_consineBottom)), (sim_movie2, ((sim_pair), sim_movie2_consineBottom))\n",
    "coleasedConsine = consineTop.flatMap(lambda data: [(data[0][0], data), (data[0][1], data)]).join(consineBottom)\n",
    "\n",
    "# Output: ((sim_pair), sim_movie1_consineBottom), ((sim_pair), sim_movie2_consineBottom) =>  ((sim_pair), sim_movie1_consineBottom*sim_movie2_consineBottom)\n",
    "finalResult = coleasedConsine.map(lambda data: (data[1][0], data[1][1])).reduceByKey(lambda x, y: x*y)\n",
    "\n",
    "# Output: ((sim_movie_id1, sim_movie_id2), consineTop/consineBottom)\n",
    "finalResult = finalResult.map(lambda data: (data[0][0], data[0][1]/data[1]))\n",
    "\n",
    "finalResultList = finalResult.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalResultList[:10]\n",
    "file1 = open(\"basic_output_small.txt\",\"w\") \n",
    "for finalResult in finalResultList:\n",
    "    file1.write(\"(%d, %d), %.6f\\n\"%(finalResult[0][0], finalResult[0][1], finalResult[1])) \n",
    "file1.close() #to change file access modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, [(2, 4.0), (3, 1.0), (5, 3.0)]),\n",
       " (8, [(4, 4.0), (6, 2.0)]),\n",
       " (12, [(2, 3.0), (5, 5.0)]),\n",
       " (1, [(1, 1.0), (3, 2.0), (6, 1.0)]),\n",
       " (5, [(3, 2.0), (4, 5.0), (5, 4.0), (6, 3.0)]),\n",
       " (9, [(1, 5.0), (3, 4.0)]),\n",
       " (2, [(3, 4.0), (4, 2.0)]),\n",
       " (6, [(1, 5.0), (5, 2.0)]),\n",
       " (10, [(2, 2.0), (3, 3.0)]),\n",
       " (3, [(1, 3.0), (2, 5.0), (4, 4.0), (5, 4.0), (6, 3.0)]),\n",
       " (7, [(2, 4.0), (3, 3.0)]),\n",
       " (11, [(1, 4.0), (2, 1.0), (3, 5.0), (4, 2.0), (5, 2.0), (6, 4.0)])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output: ((movie_id1, movie_id2), sim)\n",
    "def bonusRead(lines):\n",
    "    output = []\n",
    "    for perLine in lines.splitlines():\n",
    "        splitedItems = perLine.split(',')\n",
    "        sim = float(splitedItems[2][1:])\n",
    "        if sim <= 0: continue\n",
    "        output.append(((int(splitedItems[0][1:]), int(splitedItems[1][1:-1])), sim))\n",
    "    return output\n",
    "\n",
    "def rankingSim(data):\n",
    "    simMovieList = data[1]\n",
    "    sortedSimMovieList = sorted(simMovieList, key = lambda data: data[1], reverse=True)\n",
    "    return (data[0], sortedSimMovieList)\n",
    "    \n",
    "\n",
    "bonusData = sc.textFile(\"./basic_output_small.txt\").flatMap(bonusRead)\n",
    "\n",
    "# Output: (movie_id, [(sim_movie_id1, sim1), (sim_movie_id2, sim2), ...])\n",
    "movieSims = bonusData.flatMap(lambda data: [(data[0][0], [(data[0][1], data[1])]), (data[0][1], [(data[0][0], data[1])])]).reduceByKey(lambda x, y: x+y).map(rankingSim)\n",
    "\n",
    "# Output: (user_id, [(rated_movie_id1, rating1), (rated_movie_id2, rating2), ...])\n",
    "userMoviesRating = originalData.map(lambda data: (data[1][0], [(data[0], data[1][1])])).reduceByKey(lambda x, y: x+y)\n",
    "\n",
    "allMovieIdList = originalData.map(lambda data: data[0]).distinct().collect()\n",
    "movieSimsList = movieSims.collect()\n",
    "\n",
    "userMoviesRating.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((4, 4), 3.5050030051481373),\n",
       " ((4, 1), 1.0),\n",
       " ((4, 6), 1.0),\n",
       " ((8, 1), 2.0),\n",
       " ((8, 5), 4.0),\n",
       " ((8, 2), 4.0),\n",
       " ((8, 3), 2.0),\n",
       " ((12, 4), 3.989993989703726),\n",
       " ((5, 1), 2.5864072665593825),\n",
       " ((5, 2), 4.539852050768296),\n",
       " ((9, 6), 4.5368891815512935),\n",
       " ((2, 1), 4.0),\n",
       " ((2, 5), 2.0),\n",
       " ((2, 6), 4.0),\n",
       " ((2, 2), 2.0),\n",
       " ((6, 4), 2.0),\n",
       " ((6, 6), 5.0),\n",
       " ((6, 2), 2.0),\n",
       " ((6, 3), 5.0),\n",
       " ((10, 4), 2.0),\n",
       " ((10, 1), 3.0),\n",
       " ((10, 5), 2.0),\n",
       " ((10, 6), 3.0),\n",
       " ((3, 3), 2.9999999999999996),\n",
       " ((7, 4), 4.0),\n",
       " ((7, 1), 3.0),\n",
       " ((7, 5), 4.0),\n",
       " ((7, 6), 3.0)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predictMovieRating(data, allMovieIdList, movieSimsList):\n",
    "    ratedMovieIdList = [ pair[0] for pair in data[1] ] # Pure ids\n",
    "    missingRatedMovieIds = [item for item in allMovieIdList if item not in ratedMovieIdList] # Pure ids\n",
    "    movieSimsDict = dict(movieSimsList) # { movie_id: [(sim_movie_id, sim), ...]}\n",
    "    ratedMovieDict = dict(data[1]) # { movie_id: rating }\n",
    "    \n",
    "    finalResult = []\n",
    "\n",
    "    for missingMovieId in missingRatedMovieIds:\n",
    "        if (missingMovieId not in movieSimsDict): continue # If some movie has no any relationship with others (such as negative relationship we preprocess before), we don't need to calculate for them\n",
    "        highSimMovies = movieSimsDict[missingMovieId]\n",
    "        accumulateSim = 0 # Lower\n",
    "        accumulateRating = 0 # Upper\n",
    "        count = 0\n",
    "        for highSimMovie in highSimMovies:\n",
    "            highSimMovieId = highSimMovie[0]\n",
    "            highSimMovieSimilarity = highSimMovie[1]\n",
    "            if (highSimMovieId in ratedMovieDict):\n",
    "                # RATED BEFORE\n",
    "                accumulateRating = accumulateRating + ratedMovieDict[highSimMovieId]*highSimMovieSimilarity\n",
    "                accumulateSim = accumulateSim + highSimMovieSimilarity\n",
    "                count = count + 1\n",
    "            if (count >= 10): break\n",
    "        # If all the ratings the user predicted don't match any highly similiar movies' rating, we don't predict the rating for him\n",
    "        if (accumulateRating != 0): finalResult.append(((data[0], missingMovieId), (accumulateRating/accumulateSim)))\n",
    "    return finalResult\n",
    "\n",
    "bonusResult = userMoviesRating.flatMap(lambda x: predictMovieRating(x, allMovieIdList, movieSimsList))\n",
    "\n",
    "bonusFinalResult = bonusResult.collect()\n",
    "\n",
    "bonusFinalResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = open(\"bonus_output_small.txt\",\"w\") \n",
    "for finalResult in bonusFinalResult:\n",
    "    file1.write(\"(%d, %d), %.2f\\n\"%(finalResult[0][0], finalResult[0][1], finalResult[1])) \n",
    "file1.close() #to change file access modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
